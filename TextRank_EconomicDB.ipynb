{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "#Hindu Business Line RSS Feed\n",
    "url = \"https://economictimes.indiatimes.com/rssfeedstopstories.cms\"\n",
    "\n",
    "resp = requests.get(url)\n",
    "\n",
    "bsObj = BeautifulSoup(resp.content, features = \"xml\")\n",
    "links = bsObj.findAll('link', text=True)\n",
    "\n",
    "##Links extracted from RSS Feed\n",
    "print('EXTRACTED LINKS FROM RSS FEED')\n",
    "for link in links:\n",
    "    if(link.get_text()==\"https://economictimes.indiatimes.com\"):\n",
    "        links.remove(link)\n",
    "\n",
    "for link in links:\n",
    "    print(link.getText())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pagerank and textrank to get the summary\n",
    "\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import *\n",
    "db = create_engine('sqlite:///economicDB.db', echo=True)\n",
    "\n",
    "metadata = MetaData(db)\n",
    "\n",
    "news = Table('news', metadata,\n",
    "            Column('id', Integer, primary_key=True),\n",
    "            Column('paperName', String(100)),\n",
    "            Column('title', String(250)),\n",
    "            Column('summary', String(10000))\n",
    "            )\n",
    "news.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from operator import itemgetter \n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Store all text in list\n",
    "article_text = []\n",
    "article_title = []\n",
    "\n",
    "\n",
    "for link in links:\n",
    "    print(link)\n",
    "    article = Article(link.getText(), language=\"en\")\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    if(len(article.text.split('.'))<=3):\n",
    "        continue\n",
    "    article_text.append(article.text)\n",
    "    article_title.append(article.title)\n",
    "    print('added')\n",
    "article_text.pop(0)\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def build_similarity_matrix(sentences, stopwords=None):\n",
    "    \n",
    "    # Create an empty similarity matrix\n",
    "    S = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2:\n",
    "                continue\n",
    " \n",
    "            S[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    " \n",
    "    # normalize the matrix row-wise\n",
    "    \n",
    "    for idx in range(len(S)):\n",
    "        if(S[idx].sum()==0):\n",
    "            break\n",
    "        S[idx] /= S[idx].sum()\n",
    " \n",
    "    return S\n",
    "\n",
    "def pagerank(A, eps=0.0001, d=0.85):\n",
    "    P = np.ones(len(A)) / len(A)\n",
    "    while True:\n",
    "        new_P = np.ones(len(A)) * (1 - d) / len(A) + d * A.T.dot(P)\n",
    "        delta = abs(new_P - P).sum()\n",
    "        if delta <= eps:\n",
    "            return new_P\n",
    "        P = new_P\n",
    "\n",
    "\n",
    "temp = \"\"\n",
    "counter = 0\n",
    "i = news.insert()\n",
    "for texts in article_text:\n",
    "    sentences = sent_tokenize(texts)\n",
    "    S = build_similarity_matrix(sentences, stop_words)  \n",
    "    sentence_ranks = pagerank(S)\n",
    "    ranked_sentence_indexes = [item[0] for item in sorted(enumerate(sentence_ranks), key=lambda item: -item[1])]\n",
    "    SUMMARY_SIZE = 3\n",
    "    SELECTED_SENTENCES = sorted(ranked_sentence_indexes[:SUMMARY_SIZE])\n",
    "    summary = itemgetter(*SELECTED_SENTENCES)(sentences)\n",
    "    # Print the actual summary\n",
    "    print('\\nSUMMARY')\n",
    "    print('------------------------------')\n",
    "    for sentence in summary:\n",
    "        temp+=(''.join(sentence))\n",
    "        print(''.join(sentence), end=\"\")\n",
    "    print()\n",
    "    i.execute({'paperName':'Economic times', 'title':article_title[counter],'summary':temp})\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = news.select()\n",
    "rs = s.execute()\n",
    "\n",
    "for row in rs:\n",
    "    print(row.title, '\\n\\n', row.summary)\n",
    "    print()\n",
    "    print('====================================================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
